{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPFDxziPiiMLb2syo6sMXXP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d7fe55498e5f4c14a479adc2583a10d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e0fbcc6c51c4eed864cc9f3c7fd468d",
              "IPY_MODEL_614f93a43e044da09cbba68488d8ea8c",
              "IPY_MODEL_7c524697c3264148abaca70bd2ccb078"
            ],
            "layout": "IPY_MODEL_20daec9cd3bc4bfa9129ca1f0959f3f9"
          }
        },
        "6e0fbcc6c51c4eed864cc9f3c7fd468d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbff479e5572419692594158ef8fb802",
            "placeholder": "​",
            "style": "IPY_MODEL_e8db1c698dd74b6c8797104f229c4602",
            "value": "100%"
          }
        },
        "614f93a43e044da09cbba68488d8ea8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83e9ec9d5a9c42c7b2e85aa6a607fae1",
            "max": 1089,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c94c84aab0747a3bdbfc7b29de38168",
            "value": 1089
          }
        },
        "7c524697c3264148abaca70bd2ccb078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ade72f87e7c441ba6af00781cde11e6",
            "placeholder": "​",
            "style": "IPY_MODEL_b4daffb9f49948cc942b6dfb9bb9cfd5",
            "value": " 1089/1089 [15:58&lt;00:00,  1.30it/s]"
          }
        },
        "20daec9cd3bc4bfa9129ca1f0959f3f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbff479e5572419692594158ef8fb802": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8db1c698dd74b6c8797104f229c4602": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83e9ec9d5a9c42c7b2e85aa6a607fae1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c94c84aab0747a3bdbfc7b29de38168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ade72f87e7c441ba6af00781cde11e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4daffb9f49948cc942b6dfb9bb9cfd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TanDuong986/GCN_Vietnamese_invoice/blob/combination/Gen_Data_GCN_VN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ecn4klLy1ZvJ"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "gdown.download(url='https://drive.google.com/file/d/1KOKuhPErYlJs7l_54lNYfa4Z0DOFMQlm/view',fuzzy=True)\n",
        "!unzip /content/preprocessed_data.zip -d /content/\n",
        "!unzip /content/preprocessed_data/images.zip -d /content/preprocessed_data/\n",
        "%cd /content/preprocessed_data/\n",
        "!mkdir label_mcocr2021\n",
        "!mkdir material"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric\n",
        "!pip install gdown\n",
        "!pip install bpemb\n",
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "pcCzQB8g30U1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare part"
      ],
      "metadata": {
        "id": "z33pNFI9bSYN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert label"
      ],
      "metadata": {
        "id": "h1T7hODp3auM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import csv\n",
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "def convert_to_list_of_integers(input_string):\n",
        "    return ast.literal_eval(input_string)\n",
        "\n",
        "def convert_to_list(input_string):\n",
        "    # Remove leading '[' and trailing ']' from the string and split by comma\n",
        "    return [int(num) for num in input_string[1:-1].split(', ')]\n",
        "\n",
        "col = ['cells', 'poly', 'cate_id', 'cate_text', 'vietocr_text', 'group_id']\n",
        "with open('/content/preprocessed_data/mcocr_labels.json','r') as f:\n",
        "    data = json.load(f)\n",
        "for i in data.keys(): #name of all image\n",
        "    employee_data = data[i]\n",
        "    df = pd.DataFrame(employee_data[\"cells\"],columns=[\"poly\", \"cate_id\", \"cate_text\", \"vietocr_text\", \"group_id\"])\n",
        "    df.drop([\"group_id\"], axis=1, inplace=True)\n",
        "    df.to_csv('/content/preprocessed_data/label_mcocr2021/'+str(i) + '.csv',index=False)"
      ],
      "metadata": {
        "id": "tPwF9HG22HQO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graph class\n"
      ],
      "metadata": {
        "id": "Lwh6hnZZ3gVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Grapher:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "            This class is used to generate:\n",
        "                    1) the graph (in dictionary form) { source_node: [destination_node1, destination_node2]}\n",
        "                    2) the dataframe with relative_distances\n",
        "\n",
        "    Inputs: The class consists of a pandas dataframe consisting of cordinates for bounding boxe and the image of the invoice/receipt.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, filename, data_fd):\n",
        "        self.filename = filename\n",
        "        self.data_fd = data_fd\n",
        "\n",
        "        # tim path den file label box\n",
        "        file_path = os.path.join(self.data_fd, \"label_mcocr2021\",filename + '.jpg.csv')\n",
        "\n",
        "        #path cua image roi - concat file name -> absolute path of image\n",
        "        image_path = os.path.join(self.data_fd, \"images\", filename + '.jpg')\n",
        "\n",
        "        #read box file not have label\n",
        "        with open(file_path,'r') as f:\n",
        "            self.df = pd.read_csv(f)\n",
        "        # self.df.drop([\"cells index\",\"cate_id\",\"group_id\"], axis=1, inplace=True)\n",
        "\n",
        "        #read that image\n",
        "        self.image = cv2.imread(image_path)\n",
        "\n",
        "    def convert_to_list(self,input_string):\n",
        "        return [int(num) for num in input_string[1:-1].split(', ')]\n",
        "\n",
        "    def graph_formation(self, export_graph = False):\n",
        "        df, image = self.df, self.image\n",
        "        \"\"\"\n",
        "        preprocessing the raw csv files to favorable df\n",
        "        \"\"\"\n",
        "        df['poly'] = df['poly'].apply(self.convert_to_list)\n",
        "\n",
        "        # Create separate columns for each element in the lists\n",
        "        df_split = pd.DataFrame(df['poly'].to_list(), columns=[f'pos{i+1}' for i in range(8)])\n",
        "\n",
        "        # Concatenate the original DataFrame with the new split columns\n",
        "        df = pd.concat([ df_split,df], axis=1)\n",
        "\n",
        "        # Drop the original column with the string representations of lists\n",
        "        df.drop(['poly','pos3','pos4','pos7','pos8'], axis=1, inplace=True)\n",
        "        new_name_and_order = {'pos1':'xmin','pos2':'ymin','pos5':'xmax','pos6':'ymax','cate_id':'label_id','cate_text':'label_text','vietocr_text':'content'}\n",
        "        # column = ['label_id','label_text','content','xmin','ymin','xmax','ymax']\n",
        "        df = df[list(new_name_and_order.keys())].rename(columns=new_name_and_order)\n",
        "        for col in df.columns:\n",
        "            try:\n",
        "                df[col] = df[col].str.strip()\n",
        "            except AttributeError:\n",
        "                pass\n",
        "\n",
        "\n",
        "        df.dropna(inplace=True)\n",
        "        #sort from top to bottom\n",
        "        df.sort_values(by=['ymin'], inplace=True)\n",
        "        df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "        #subtracting ymax by 1 to eliminate ambiguity of boxes being in both left and right\n",
        "        df[\"ymax\"] = df[\"ymax\"].apply(lambda x: x - 1)\n",
        "\n",
        "        master = []\n",
        "        for idx, row in df.iterrows():\n",
        "            # print(idx,row)\n",
        "            #flatten the nested list\n",
        "            flat_master = list(itertools.chain(*master))\n",
        "            #check to see if idx is in flat_master\n",
        "            if idx not in flat_master:\n",
        "                top_a = row['ymin']\n",
        "                bottom_a = row['ymax']\n",
        "                #every line will atleast have the word in it\n",
        "                line = [idx]\n",
        "                for idx_2, row_2 in df.iterrows():\n",
        "                    #check to see if idx_2 is in flat_master removes ambiguity\n",
        "                    #picks higher cordinate one.\n",
        "                    if idx_2 not in flat_master:\n",
        "                    #if not the same words\n",
        "                        if not idx == idx_2:\n",
        "                            top_b = row_2['ymin']\n",
        "                            bottom_b = row_2['ymax']\n",
        "                            if (top_a <= bottom_b) and (bottom_a >= top_b):\n",
        "                                line.append(idx_2)\n",
        "                master.append(line)\n",
        "        df2 = pd.DataFrame({'words_indices': master, 'line_number':[x for x in range(1,len(master)+1)]})\n",
        "        #explode the list columns eg : [1,2,3]\n",
        "        df2 = df2.set_index('line_number').words_indices.apply(pd.Series).stack()\\\n",
        "                .reset_index(level=0).rename(columns={0:'words_indices'})\n",
        "        df2['words_indices'] = df2['words_indices'].astype('int')\n",
        "        #put the line numbers back to the list\n",
        "        final = df.merge(df2, left_on=df.index, right_on='words_indices')\n",
        "        final.drop('words_indices', axis=1, inplace=True)\n",
        "\n",
        "        \"\"\"\n",
        "        3) Sort words in each line based on Left coordinate\n",
        "        \"\"\"\n",
        "        final2 =final.sort_values(by=['line_number','xmin'],ascending=True)\\\n",
        "                .groupby('line_number')\\\n",
        "                .head(len(final))\\\n",
        "                .reset_index(drop=True)\n",
        "\n",
        "        df = final2\n",
        "\n",
        "        df.reset_index(inplace=True)\n",
        "        grouped = df.groupby('line_number')\n",
        "        #for undirected graph construction\n",
        "        horizontal_connections = {}\n",
        "        #left\n",
        "        left_connections = {}\n",
        "        #right\n",
        "        right_connections = {}\n",
        "        for _,group in grouped:\n",
        "            # print(group)\n",
        "            a = group['index'].tolist()\n",
        "            b = group['index'].tolist()\n",
        "            horizontal_connection = {a[i]:a[i+1] for i in range(len(a)-1) }\n",
        "            #storing directional connections\n",
        "            right_dict_temp = {a[i]:{'right':a[i+1]} for i in range(len(a)-1) }\n",
        "            left_dict_temp = {b[i+1]:{'left':b[i]} for i in range(len(b)-1) }\n",
        "\n",
        "            #add the indices in the dataframes\n",
        "            for i in range(len(a)-1):\n",
        "                df.loc[df['index'] == a[i], 'right'] = int(a[i+1])\n",
        "                df.loc[df['index'] == a[i+1], 'left'] = int(a[i])\n",
        "\n",
        "            left_connections.update(right_dict_temp)\n",
        "            right_connections.update(left_dict_temp)\n",
        "            horizontal_connections.update(horizontal_connection)\n",
        "\n",
        "        dic1,dic2 = left_connections, right_connections\n",
        "\n",
        "        #verticle connections formation\n",
        "        bottom_connections = {}\n",
        "        top_connections = {}\n",
        "\n",
        "        for idx, row in df.iterrows():\n",
        "            if idx not in bottom_connections.keys():\n",
        "                right_a = row['xmax']\n",
        "                left_a = row['xmin']\n",
        "\n",
        "                for idx_2, row_2 in df.iterrows():\n",
        "                    #check for higher idx values\n",
        "\n",
        "                    if idx_2 not in bottom_connections.values() and idx < idx_2:\n",
        "                            right_b = row_2['xmax']\n",
        "                            left_b = row_2['xmin']\n",
        "                            if (left_b <= right_a) and (right_b >= left_a):\n",
        "                                bottom_connections[idx] = idx_2\n",
        "                                top_connections[idx_2] = idx\n",
        "\n",
        "                                #add it to the dataframe\n",
        "                                df.loc[df['index'] == idx , 'bottom'] = idx_2\n",
        "                                df.loc[df['index'] == idx_2, 'top'] = idx\n",
        "                                #print(bottom_connections)\n",
        "                                #once the condition is met, break the loop to reduce redundant time complexity\n",
        "                                break\n",
        "\n",
        "        #combining both\n",
        "        result = {}\n",
        "        dic1 = horizontal_connections\n",
        "        dic2 = bottom_connections\n",
        "\n",
        "        for key in (dic1.keys() | dic2.keys()):\n",
        "            if key in dic1: result.setdefault(key, []).append(dic1[key])\n",
        "            if key in dic2: result.setdefault(key, []).append(dic2[key])\n",
        "        # print(result)\n",
        "\n",
        "        G = nx.from_dict_of_lists(result)\n",
        "\n",
        "        if export_graph:\n",
        "            here = os.path.dirname(os.path.abspath(__file__))\n",
        "            should_save_dir = os.path.join(here,'figures/')\n",
        "            if not os.path.exists(should_save_dir):\n",
        "                os.makedirs(should_save_dir)\n",
        "\n",
        "            plot_path = should_save_dir + self.filename + 'plain_graph' '.jpg'\n",
        "            # print(plot_path)\n",
        "            layout = nx.kamada_kawai_layout(G)\n",
        "            layout = nx.spring_layout(G)\n",
        "            nx.draw(G, layout, with_labels=True)\n",
        "            plt.savefig(plot_path, format=\"JPG\", dpi=600)\n",
        "            #plt.show()\n",
        "\n",
        "        # connect with the interim file that has labels in it\n",
        "        # df['labels'] = self.df_withlabels['9']\n",
        "        self.df = df\n",
        "        return G,result, df\n",
        "\n",
        "\n",
        "    def get_text_features(self, df):\n",
        "        \"\"\"\n",
        "        gets text features\n",
        "\n",
        "        Args: df\n",
        "        Returns: n_lower, n_upper, n_spaces, n_alpha, n_numeric,n_special\n",
        "        \"\"\"\n",
        "        data = df['content'].tolist()\n",
        "\n",
        "        '''\n",
        "            Args:\n",
        "                df\n",
        "\n",
        "            Returns:\n",
        "                character and word features\n",
        "\n",
        "        '''\n",
        "        special_chars = ['&', '@', '#', '(',')','-','+',\n",
        "                    '=', '*', '%', '.', ',', '\\\\','/',\n",
        "                    '|', ':']\n",
        "\n",
        "        # character wise\n",
        "        n_lower, n_upper, n_spaces, n_alpha, n_numeric,n_special = [],[],[],[],[],[]\n",
        "\n",
        "        for words in data:\n",
        "            lower, upper,alpha,spaces,numeric,special = 0,0,0,0,0,0\n",
        "            for char in words:\n",
        "                if char.islower():\n",
        "                    lower += 1\n",
        "                # for upper letters\n",
        "                if char.isupper():\n",
        "                    upper += 1\n",
        "                # for white spaces\n",
        "                if char.isspace():\n",
        "                    spaces += 1\n",
        "                # for alphabetic chars\n",
        "                if char.isalpha():\n",
        "                    alpha += 1\n",
        "                # for numeric chars\n",
        "                if char.isnumeric():\n",
        "                    numeric += 1\n",
        "                if char in special_chars:\n",
        "                    special += 1\n",
        "\n",
        "            n_lower.append(lower)\n",
        "            n_upper.append(upper)\n",
        "            n_spaces.append(spaces)\n",
        "            n_alpha.append(alpha)\n",
        "            n_numeric.append(numeric)\n",
        "            n_special.append(special)\n",
        "            #features.append([n_lower, n_upper, n_spaces, n_alpha, n_numeric, n_digits])\n",
        "\n",
        "        df['n_upper'],df['n_alpha'],df['n_spaces'],\\\n",
        "        df['n_numeric'],df['n_special'] = n_upper, n_alpha, n_spaces, n_numeric,n_special\n",
        "\n",
        "    def relative_distance(self, export_document_graph = False):\n",
        "        \"\"\"\n",
        "        1) Calculates relative distances for each node in left, right, top  and bottom directions if they exist.\n",
        "        rd_l, rd_r = relative distances left , relative distances right. The distances are divided by image width\n",
        "        rd_t, rd_b = relative distances top , relative distances bottom. The distances are divided by image length\n",
        "\n",
        "        2) Exports the complete document graph for visualization\n",
        "\n",
        "        Args:\n",
        "            result dataframe from graph_formation()\n",
        "\n",
        "        returns:\n",
        "            dataframe with features and exports document graph if prompted\n",
        "        \"\"\"\n",
        "\n",
        "        df, img = self.df, self.image\n",
        "        image_height, image_width = self.image.shape[0], self.image.shape[1]\n",
        "        plot_df = df.copy()\n",
        "        for index in df['index'].to_list():\n",
        "            right_index = df.loc[df['index'] == index, 'right'].values[0]\n",
        "            left_index = df.loc[df['index'] == index, 'left'].values[0]\n",
        "            bottom_index = df.loc[df['index'] == index, 'bottom'].values[0]\n",
        "            top_index = df.loc[df['index'] == index, 'top'].values[0]\n",
        "\n",
        "            #check if it is nan value\n",
        "            if np.isnan(right_index) == False:\n",
        "                right_word_left = df.loc[df['index'] == right_index, 'xmin'].values[0]\n",
        "                source_word_right = df.loc[df['index'] == index, 'xmax'].values[0]\n",
        "                df.loc[df['index'] == index, 'rd_r'] = (right_word_left - source_word_right)/image_width\n",
        "\n",
        "                \"\"\"\n",
        "                for plotting purposes\n",
        "                getting the mid point of the values to draw the lines for the graph\n",
        "                mid points of source and destination for the bounding boxes\n",
        "                \"\"\"\n",
        "                right_word_x_max = df.loc[df['index'] == right_index, 'xmax'].values[0]\n",
        "                right_word_y_max = df.loc[df['index'] == right_index, 'ymax'].values[0]\n",
        "                right_word_y_min = df.loc[df['index'] == right_index, 'ymin'].values[0]\n",
        "\n",
        "                df.loc[df['index'] == index, 'destination_x_hori'] = (right_word_x_max + right_word_left)/2\n",
        "                df.loc[df['index'] == index, 'destination_y_hori'] = (right_word_y_max + right_word_y_min)/2\n",
        "\n",
        "            if np.isnan(left_index) == False:\n",
        "                left_word_right = df.loc[df['index'] == left_index, 'xmax'].values[0]\n",
        "                source_word_left = df.loc[df['index'] == index, 'xmin'].values[0]\n",
        "                df.loc[df['index'] == index, 'rd_l'] = (left_word_right - source_word_left)/image_width\n",
        "\n",
        "            if np.isnan(bottom_index) == False:\n",
        "                bottom_word_top = df.loc[df['index'] == bottom_index, 'ymin'].values[0]\n",
        "                source_word_bottom = df.loc[df['index'] == index, 'ymax'].values[0]\n",
        "                df.loc[df['index'] == index, 'rd_b'] = (bottom_word_top - source_word_bottom)/image_height\n",
        "\n",
        "                \"\"\"for plotting purposes\"\"\"\n",
        "                bottom_word_top_max = df.loc[df['index'] == bottom_index, 'ymax'].values[0]\n",
        "                bottom_word_x_max = df.loc[df['index'] == bottom_index, 'xmax'].values[0]\n",
        "                bottom_word_x_min = df.loc[df['index'] == bottom_index, 'xmin'].values[0]\n",
        "                df.loc[df['index'] == index, 'destination_y_vert'] = (bottom_word_top_max + bottom_word_top)/2\n",
        "                df.loc[df['index'] == index, 'destination_x_vert'] = (bottom_word_x_max + bottom_word_x_min)/2\n",
        "\n",
        "            if np.isnan(top_index) == False:\n",
        "                top_word_bottom = df.loc[df['index'] == top_index, 'ymax'].values[0]\n",
        "                source_word_top = df.loc[df['index'] == index, 'ymin'].values[0]\n",
        "                df.loc[df['index'] == index, 'rd_t'] = (top_word_bottom - source_word_top)/image_height\n",
        "\n",
        "        #replace all tne NaN values with '0' meaning there is nothing in that direction\n",
        "        df[['rd_r','rd_b','rd_l','rd_t']] = df[['rd_r','rd_b','rd_l','rd_t']].fillna(0)\n",
        "\n",
        "        if export_document_graph:\n",
        "            for idx, row in df.iterrows():\n",
        "        #bounding box\n",
        "                cv2.rectangle(img, (row['xmin'], row['ymin']), (row['xmax'], row['ymax']), (0, 0, 255), 2)\n",
        "\n",
        "                if np.isnan(row['destination_x_vert']) == False:\n",
        "                    source_x = (row['xmax'] + row['xmin'])/2\n",
        "                    source_y = (row['ymax'] + row['ymin'])/2\n",
        "\n",
        "                    cv2.line(img,\n",
        "                            (int(source_x), int(source_y)),\n",
        "                            (int(row['destination_x_vert']), int(row['destination_y_vert'])),\n",
        "                            (0,255,0), 2)\n",
        "\n",
        "\n",
        "                    text = \"{:.3f}\".format(row['rd_b'])\n",
        "                    text_coordinates = ( int((row['destination_x_vert'] + source_x)/2) , int((row['destination_y_vert'] +source_y)/2))\n",
        "                    cv2.putText(img, text, text_coordinates, cv2.FONT_HERSHEY_DUPLEX, 0.4, (255,0,0), 1)\n",
        "\n",
        "                    #text_coordinates = ((row['destination_x_vert'] + source_x)/2 , (row['destination_y_vert'] +source_y)/2)\n",
        "\n",
        "                if np.isnan(row['destination_x_hori']) == False:\n",
        "                    source_x = (row['xmax'] + row['xmin'])/2\n",
        "                    source_y = (row['ymax'] + row['ymin'])/2\n",
        "\n",
        "                    cv2.line(img,\n",
        "                        (int(source_x), int(source_y)),\n",
        "                        (int(row['destination_x_hori']), int(row['destination_y_hori'])), \\\n",
        "                        (0,255,0), 2)\n",
        "\n",
        "                    text = \"{:.3f}\".format(row['rd_r'])\n",
        "                    text_coordinates = (int((row['destination_x_hori'] + source_x)/2) , int((row['destination_y_hori'] +source_y)/2))\n",
        "                    cv2.putText(img, text, text_coordinates, cv2.FONT_HERSHEY_DUPLEX, 0.4, (255,0,0), 1)\n",
        "\n",
        "            # cv2.imshow(\"image\", img)\n",
        "            # cv2.waitKey(0)\n",
        "            # cv2.destroyAllWindows()\n",
        "                if not os.path.exists('../../figures/graphs'):\n",
        "                    os.makedirs('../../figures/graphs')\n",
        "\n",
        "                plot_path ='../../figures/graphs/' + self.filename + 'docu_graph' '.jpg'\n",
        "                cv2.imwrite(plot_path, img)\n",
        "\n",
        "        #drop the unnecessary columns\n",
        "        df.drop(['destination_x_hori', 'destination_y_hori','destination_y_vert','destination_x_vert'], axis=1, inplace=True)\n",
        "        self.get_text_features(df)\n",
        "        return df"
      ],
      "metadata": {
        "id": "EeovPAtk2_y2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate data"
      ],
      "metadata": {
        "id": "BDgmLGhq3jkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "from torch_geometric.utils.convert import from_networkx\n",
        "from torch_geometric.nn.conv import ChebConv,GCNConv\n",
        "import torch_geometric\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "from numpy import random\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "data_fd ='/content/preprocessed_data'\n",
        "label_pth = os.path.join(data_fd,'label_mcocr2021')\n",
        "save_fd = '/content/preprocessed_data/material'\n",
        "\n",
        "\n",
        "sent_model = SentenceTransformer('keepitreal/vietnamese-sbert')\n",
        "def make_sent_bert_features(text):\n",
        "    emb = sent_model.encode([text])[0]\n",
        "    return emb\n",
        "\n",
        "# def get_data(save_fd):\n",
        "#     \"\"\"\n",
        "#     returns one big graph with unconnected graphs with the following:\n",
        "#     - x (Tensor, optional) – Node feature matrix with shape [num_nodes, num_node_features]. (default: None)\n",
        "#     - edge_index (LongTensor, optional) – Graph connectivity in COO format with shape [2, num_edges]. (default: None)\n",
        "#     - edge_attr (Tensor, optional) – Edge feature matrix with shape [num_edges, num_edge_features]. (default: None)\n",
        "#     - y (Tensor, optional) – Graph or node targets with arbitrary shape. (default: None)\n",
        "#     - validation mask, training mask and testing mask\n",
        "#     \"\"\"\n",
        "\n",
        "path = label_pth\n",
        "files = [i.split('.')[0] for i in os.listdir(path)]\n",
        "files.sort()\n",
        "# error_id = unique()\n",
        "all_files = files[1:] # don't take the first file, this is header\n",
        "# all_files = list(set(all_files) - set(error_id))\n",
        "# all_files.sort()\n",
        "\n",
        "list_of_graphs = []\n",
        "train_list_of_graphs, test_list_of_graphs = [], []\n",
        "\n",
        "files = all_files.copy()\n",
        "random.shuffle(files)\n",
        "\n",
        "\"\"\"Resulting in 550 receipts for training\"\"\"\n",
        "training, testing = files[:872], files[872:] # 80% of 1090\n",
        "\n",
        "for file in tqdm.tqdm_notebook (all_files):\n",
        "    connect = Grapher(file, data_fd)\n",
        "    G,_,_ = connect.graph_formation()\n",
        "    df = connect.relative_distance()\n",
        "    individual_data = from_networkx(G)\n",
        "    # print(df['num_labels'])\n",
        "\n",
        "    feature_cols = ['rd_b', 'rd_r', 'rd_t', 'rd_l','line_number', \\\n",
        "            'n_upper', 'n_alpha', 'n_spaces', 'n_numeric','n_special']\n",
        "\n",
        "    text_features = np.array(df[\"content\"].map(make_sent_bert_features).tolist()).astype(np.float32)\n",
        "    numeric_features = df[feature_cols].values.astype(np.float32)\n",
        "\n",
        "    features = np.concatenate((numeric_features, text_features), axis=1)\n",
        "    features = torch.tensor(features)\n",
        "\n",
        "    for col in df.columns:\n",
        "        try:\n",
        "            df[col] = df[col].str.strip()\n",
        "        except AttributeError as e:\n",
        "            pass\n",
        "\n",
        "    # df['labels'] = df['labels'].fillna('undefined')\n",
        "    df.loc[df['label_text'] == 'SELLER', 'num_labels'] = 1\n",
        "    df.loc[df['label_text'] == 'ADDRESS', 'num_labels'] = 2\n",
        "    df.loc[df['label_text'] == 'TIMESTAMP', 'num_labels'] = 3\n",
        "    df.loc[df['label_text'] == 'TOTAL_COST', 'num_labels'] = 4\n",
        "    df.loc[df['label_text'] == 'OTHER', 'num_labels'] = 5\n",
        "    # df.loc[df['labels_text'] == 'invoice', 'num_labels'] = 5 # this code do not use 'invoice' label so make it into background\n",
        "\n",
        "    assert df['num_labels'].isnull().values.any() == False, f'labeling error! Invalid label(s) present in {file}.csv'\n",
        "    labels = torch.tensor(df['num_labels'].values.astype(np.int8))\n",
        "    text = df['content'].values\n",
        "\n",
        "    individual_data.x = features\n",
        "    individual_data.y = labels\n",
        "    individual_data.text = text\n",
        "    individual_data.img_id = file\n",
        "\n",
        "    if file in training:\n",
        "        train_list_of_graphs.append(individual_data)\n",
        "    elif file in testing:\n",
        "        test_list_of_graphs.append(individual_data)\n",
        "      # df now is a data frame have 22 columns and 71 row, object is text had embedding to feature\n",
        "train_data = torch_geometric.data.Batch.from_data_list(train_list_of_graphs)\n",
        "train_data.edge_attr = None\n",
        "test_data = torch_geometric.data.Batch.from_data_list(test_list_of_graphs)\n",
        "test_data.edge_attr = None\n",
        "\n",
        "torch.save(train_data, os.path.join(save_fd, 'train_dataVN.dataset'))\n",
        "torch.save(test_data, os.path.join(save_fd, 'test_dataVN.dataset'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "d7fe55498e5f4c14a479adc2583a10d4",
            "6e0fbcc6c51c4eed864cc9f3c7fd468d",
            "614f93a43e044da09cbba68488d8ea8c",
            "7c524697c3264148abaca70bd2ccb078",
            "20daec9cd3bc4bfa9129ca1f0959f3f9",
            "bbff479e5572419692594158ef8fb802",
            "e8db1c698dd74b6c8797104f229c4602",
            "83e9ec9d5a9c42c7b2e85aa6a607fae1",
            "3c94c84aab0747a3bdbfc7b29de38168",
            "1ade72f87e7c441ba6af00781cde11e6",
            "b4daffb9f49948cc942b6dfb9bb9cfd5"
          ]
        },
        "id": "njk0YnhJ3GHz",
        "outputId": "ed15bf2b-85e5-4203-9276-ae9c961255a4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-f7ffe2ee9910>:51: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for file in tqdm.tqdm_notebook (all_files):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1089 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7fe55498e5f4c14a479adc2583a10d4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPCh09dkb7ZM",
        "outputId": "f78fc69b-6586-449b-9486-cd09940b7c7b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train part\n"
      ],
      "metadata": {
        "id": "LpIL-HhNbVvZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model class"
      ],
      "metadata": {
        "id": "2bnTu_xsa_Pd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn.conv import ChebConv,GCNConv\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class InvoiceGCN(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, chebnet=False, n_classes=5, dropout_rate=0.2, K=3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.n_classes = n_classes\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        if chebnet:\n",
        "            self.conv1 = ChebConv(self.input_dim, 64, K=K)\n",
        "            self.conv2 = ChebConv(64, 32, K=K)\n",
        "            self.conv3 = ChebConv(32, 16, K=K)\n",
        "            self.conv4 = ChebConv(16, self.n_classes, K=K)\n",
        "        else:\n",
        "            self.conv1 = GCNConv(self.first_dim, 64, improved=True, cached=True)\n",
        "            self.conv2 = GCNConv(64, 32, improved=True, cached=True)\n",
        "            self.conv3 = GCNConv(32, 16, improved=True, cached=True)\n",
        "            self.conv4 = GCNConv(16, self.n_classes, improved=True, cached=True)\n",
        "\n",
        "    def forward(self, data):\n",
        "        # for transductive setting with full-batch update\n",
        "        x, edge_index, edge_weight = data.x, data.edge_index, data.edge_attr\n",
        "\n",
        "        x = F.dropout(F.relu(self.conv1(x, edge_index, edge_weight)), p=self.dropout_rate, training=self.training)\n",
        "        x = F.dropout(F.relu(self.conv2(x, edge_index, edge_weight)), p=self.dropout_rate, training=self.training)\n",
        "        x = F.dropout(F.relu(self.conv3(x, edge_index, edge_weight)), p=self.dropout_rate, training=self.training)\n",
        "        x = self.conv4(x, edge_index, edge_weight)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "################################# different model #######################\n",
        "\n",
        "class GraphConvolution(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim,\n",
        "        output_dim,\n",
        "        dropout=0.2,\n",
        "        bias=True,\n",
        "        activation=F.relu,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        if dropout:\n",
        "            self.dropout = dropout\n",
        "        else:\n",
        "            self.dropout = 0.0\n",
        "\n",
        "        self.bias = bias\n",
        "        self.activation = activation\n",
        "\n",
        "        def glorot(shape, name=None):\n",
        "            \"\"\"Glorot & Bengio (AISTATS 2010) init.\"\"\"\n",
        "            init_range = np.sqrt(6.0 / (shape[0] + shape[1]))\n",
        "            init = torch.FloatTensor(shape[0], shape[1]).uniform_(\n",
        "                -init_range, init_range\n",
        "            )\n",
        "            return init\n",
        "\n",
        "        self.weight = nn.Parameter(glorot((input_dim, output_dim)))\n",
        "        self.bias = None\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.zeros(output_dim))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # node feature, adj matrix\n",
        "        # D^(-1/2).A.D^(-1/2).H_i.W_i\n",
        "        # with H_0 = X (init node features)\n",
        "        # V, A\n",
        "        x, support = inputs\n",
        "\n",
        "        x = F.dropout(x, self.dropout)\n",
        "        xw = torch.mm(x, self.weight)\n",
        "        out = torch.sparse.mm(support, xw)\n",
        "\n",
        "        if self.bias is not None:\n",
        "            out += self.bias\n",
        "\n",
        "        if self.activation is None:\n",
        "            return out, support\n",
        "        else:\n",
        "            return self.activation(out), support\n",
        "\n",
        "class LinearEmbedding(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, output_size, use_act=\"relu\"):\n",
        "        super().__init__()\n",
        "        self.C = output_size\n",
        "        self.F = input_size\n",
        "\n",
        "        self.W = nn.Parameter(torch.FloatTensor(self.F, self.C))\n",
        "        self.B = nn.Parameter(torch.FloatTensor(self.C))\n",
        "\n",
        "        if use_act == \"relu\":\n",
        "            self.act = torch.nn.ReLU()\n",
        "        elif use_act == \"softmax\":\n",
        "            self.act = torch.nn.Softmax(dim=-1)\n",
        "        else:\n",
        "            self.act = None\n",
        "\n",
        "        nn.init.xavier_normal_(self.W)\n",
        "        nn.init.normal_(self.B, mean=1e-4, std=1e-5)\n",
        "\n",
        "    def forward(self, V):\n",
        "        # V shape B,N,F\n",
        "        # V: node features\n",
        "        V_out = torch.matmul(V, self.W) + self.B\n",
        "        if self.act:\n",
        "            V_out = self.act(V_out)\n",
        "\n",
        "        return V_out\n",
        "\n",
        "class GCN(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, output_dim, hidden_dims=[256, 128, 64],\n",
        "                 bias=True, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dims = hidden_dims\n",
        "        self.bias = bias\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        gcn_layers = []\n",
        "        for index, (h1, h2) in enumerate(\n",
        "            zip(self.hidden_dims[:-1], self.hidden_dims[1:])):\n",
        "            gcn_layers.append(\n",
        "                GraphConvolution(\n",
        "                    h1,\n",
        "                    h2,\n",
        "                    activation=None if index == len(self.hidden_dims) else F.relu,\n",
        "                    bias=self.bias,\n",
        "                    dropout=self.dropout_rate,\n",
        "                    is_sparse_inputs=False\n",
        "                )\n",
        "            )\n",
        "\n",
        "        self.layers = nn.Sequential(*gcn_layers)\n",
        "        self.linear1 = LinearEmbedding(input_dim, self.hidden_dims[0], use_act='relu')\n",
        "        self.linear2 = LinearEmbedding(self.hidden_dims[-1], self.output_dim, use_act='relu')\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # features, adj\n",
        "        x, support = inputs\n",
        "        x = self.linear1(x)\n",
        "        x = F.dropout(x, p=self.dropout_rate)\n",
        "        x, _ = self.layers((x, support))\n",
        "        x = self.linear2(x)\n",
        "        return x, support\n"
      ],
      "metadata": {
        "id": "Yhw0BI_5a-PG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training part"
      ],
      "metadata": {
        "id": "E7-iI0VJbELA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from torch_geometric.utils.convert import from_networkx\n",
        "\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import os\n",
        "import time\n",
        "\n",
        "\n",
        "save_fd = '/content/preprocessed_data/material'\n",
        "def load_train_test_split(save_fd):\n",
        "    train_data = torch.load(os.path.join(save_fd, 'train_dataVN.dataset'))\n",
        "    test_data = torch.load(os.path.join(save_fd, 'test_dataVN.dataset'))\n",
        "    return train_data, test_data\n",
        "\n",
        "train_data, test_data = load_train_test_split(save_fd=save_fd)\n",
        "# print(train_data, test_data)\n",
        "\n",
        "model = InvoiceGCN(input_dim=train_data.x.shape[1], chebnet=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(), lr=0.001, weight_decay=0.9\n",
        ")\n",
        "train_data = train_data.to(device)\n",
        "test_data = test_data.to(device)\n",
        "\n",
        "# class weights for imbalanced data\n",
        "_class_weights = compute_class_weight(\n",
        "    class_weight=\"balanced\", classes = train_data.y.unique().cpu().numpy(), y= train_data.y.cpu().numpy()\n",
        ")\n",
        "print(_class_weights)\n",
        "\n",
        "no_epochs = 1000\n",
        "for epoch in range(1, no_epochs + 1):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # NOTE: just use boolean indexing to filter out test data, and backward after that!\n",
        "    # the same holds true with test data :D\n",
        "    # https://github.com/rusty1s/pytorch_geometric/issues/1928\n",
        "    loss = F.nll_loss(\n",
        "        model(train_data), (train_data.y - 1).to(torch.int64), weight=torch.FloatTensor(_class_weights).to(device)\n",
        "    )\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # calculate acc on 5 classes\n",
        "    with torch.no_grad():\n",
        "        if epoch % 200 == 0:\n",
        "            model.eval()\n",
        "\n",
        "            # forward model\n",
        "            for index, name in enumerate(['train', 'test']):\n",
        "                _data = eval(\"{}_data\".format(name))\n",
        "                y_pred = model(_data).max(dim=1)[1]\n",
        "                y_true = (_data.y - 1)\n",
        "                acc = y_pred.eq(y_true).sum().item() / y_pred.shape[0]\n",
        "\n",
        "                y_pred = y_pred.cpu().numpy()\n",
        "                y_true = y_true.cpu().numpy()\n",
        "                print(\"\\t{} acc: {}\".format(name, acc))\n",
        "                # confusion matrix\n",
        "                if name == 'test':\n",
        "                    cm = confusion_matrix(y_true, y_pred)\n",
        "                    class_accs = cm.diagonal() / cm.sum(axis=1)\n",
        "                    print(classification_report(y_true, y_pred))\n",
        "\n",
        "            loss_val = F.nll_loss(model(test_data), (test_data.y - 1).to(torch.int64))\n",
        "            fmt_log = \"Epoch: {:03d}, train_loss:{:.4f}, val_loss:{:.4f}\"\n",
        "            print(fmt_log.format(epoch, loss, loss_val))\n",
        "            print(\">\" * 50)\n"
      ],
      "metadata": {
        "id": "tWI9euChbHsl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7666017c-1b98-4c4f-dc96-30d44d2e4052"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6.97227723 3.79736369 6.18321951 3.81565322 0.23984106]\n",
            "\ttrain acc: 0.8366941209883556\n",
            "\ttest acc: 0.8255324418028727\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.94      0.76       225\n",
            "           1       0.62      0.97      0.75       393\n",
            "           2       0.50      0.95      0.66       243\n",
            "           3       0.32      0.84      0.46       411\n",
            "           4       0.99      0.81      0.89      6804\n",
            "\n",
            "    accuracy                           0.83      8076\n",
            "   macro avg       0.61      0.90      0.70      8076\n",
            "weighted avg       0.91      0.83      0.85      8076\n",
            "\n",
            "Epoch: 200, train_loss:0.3186, val_loss:0.4827\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "\ttrain acc: 0.9260626715895106\n",
            "\ttest acc: 0.8895492818226844\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.96      0.82       225\n",
            "           1       0.76      0.96      0.85       393\n",
            "           2       0.59      0.93      0.72       243\n",
            "           3       0.43      0.82      0.57       411\n",
            "           4       0.98      0.89      0.93      6804\n",
            "\n",
            "    accuracy                           0.89      8076\n",
            "   macro avg       0.70      0.91      0.78      8076\n",
            "weighted avg       0.93      0.89      0.90      8076\n",
            "\n",
            "Epoch: 400, train_loss:0.1492, val_loss:0.3200\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "\ttrain acc: 0.9713780807220171\n",
            "\ttest acc: 0.928429915799901\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.95      0.86       225\n",
            "           1       0.86      0.96      0.91       393\n",
            "           2       0.66      0.93      0.77       243\n",
            "           3       0.59      0.70      0.64       411\n",
            "           4       0.98      0.94      0.96      6804\n",
            "\n",
            "    accuracy                           0.93      8076\n",
            "   macro avg       0.78      0.90      0.83      8076\n",
            "weighted avg       0.94      0.93      0.93      8076\n",
            "\n",
            "Epoch: 600, train_loss:0.0882, val_loss:0.2431\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "\ttrain acc: 0.9826438196219508\n",
            "\ttest acc: 0.9357355126300149\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.95      0.90       225\n",
            "           1       0.89      0.97      0.93       393\n",
            "           2       0.69      0.91      0.79       243\n",
            "           3       0.60      0.71      0.65       411\n",
            "           4       0.98      0.95      0.96      6804\n",
            "\n",
            "    accuracy                           0.94      8076\n",
            "   macro avg       0.81      0.90      0.85      8076\n",
            "weighted avg       0.94      0.94      0.94      8076\n",
            "\n",
            "Epoch: 800, train_loss:0.0597, val_loss:0.2348\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "\ttrain acc: 0.9876613335857869\n",
            "\ttest acc: 0.9384596334819217\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.95      0.91       225\n",
            "           1       0.90      0.96      0.93       393\n",
            "           2       0.70      0.91      0.79       243\n",
            "           3       0.62      0.69      0.66       411\n",
            "           4       0.98      0.95      0.96      6804\n",
            "\n",
            "    accuracy                           0.94      8076\n",
            "   macro avg       0.82      0.89      0.85      8076\n",
            "weighted avg       0.94      0.94      0.94      8076\n",
            "\n",
            "Epoch: 1000, train_loss:0.0472, val_loss:0.2387\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing\n"
      ],
      "metadata": {
        "id": "wiLC1CwyvqRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from torch_geometric.utils.convert import from_networkx\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import Counter\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "from tqdm import tqdm_notebook\n",
        "import tqdm\n",
        "\n",
        "def make_info(img_id,data_fd ='/content/preprocessed_data',img_fd ='/content/preprocessed_data/images'):\n",
        "    connect = Grapher(img_id, data_fd)\n",
        "    G, _, _ = connect.graph_formation()\n",
        "    df = connect.relative_distance()\n",
        "    img = cv2.imread(os.path.join(img_fd, \"{}.jpg\".format(img_id)))[:, :, ::-1]\n",
        "    return G,df,img\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    save_fd = '/content/preprocessed_data/data'\n",
        "    test_output_fd = \"/content/preprocessed_data/output_fd\"\n",
        "\n",
        "    test_data = torch.load(os.path.join(save_fd, 'test_dataVN.dataset'))\n",
        "    if not os.path.exists(test_output_fd):\n",
        "        os.mkdir(test_output_fd)\n",
        "    model = InvoiceGCN(input_dim=test_data.x.shape[1],chebnet=True) #778 is sum of 768 [embedding] + 10 [spatial and text properties]\n",
        "    model.load_state_dict(torch.load('/content/preprocessed_data/weight/model_std.pt'))\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "    test_data = test_data.to(device)\n",
        "\n",
        "    y_preds = model(test_data).max(dim=1)[1].cpu().numpy()\n",
        "    LABELS = [\"Nguoi ban\", \"Dia chi\", \"Ngay ban\", \"Thanh toan\", \"Khac\"]\n",
        "    test_batch = test_data.batch.cpu().numpy()\n",
        "    # an array contains information about location of each cell of each sample\n",
        "    # [ 0 0 0 0 1 1 1 1 1 2 2 2 2 2 .....] 217 sample, loss 1 sample of testing (null)\n",
        "    indexes = range(len(test_data.img_id))\n",
        "\n",
        "    # with tqdm(total=total) as pbar:\n",
        "    for index in tqdm_notebook(indexes):\n",
        "        start = time.time()\n",
        "        img_id = test_data.img_id[index]\n",
        "        sample_indexes = np.where(test_batch == index)[0]\n",
        "        y_pred = y_preds[sample_indexes]\n",
        "\n",
        "        print(\"Img index: {}\".format(index))\n",
        "        print(\"Img id: {}\".format(img_id))\n",
        "        print(\"y_pred: {}\".format(Counter(y_pred)))\n",
        "        G,df,img = make_info(img_id)\n",
        "\n",
        "        assert len(y_pred) == df.shape[0]\n",
        "\n",
        "        img2 = np.copy(img)\n",
        "        for row_index, row in df.iterrows():\n",
        "            x1,y1,x2,y2 = row[['xmin','ymin','xmax','ymax']]\n",
        "            true_label = row['label_text']\n",
        "\n",
        "            # if isinstance(true_label,str) and true_label != \"invoice\":\n",
        "            #     cv2.rectangle(img2,(x1,y1),(x2,y2),(0,255,0),2)\n",
        "\n",
        "            y_pred_ = y_pred[row_index]\n",
        "            if y_pred_ != 4:\n",
        "                cv2.rectangle(img2,(x1,y1),(x2,y2),(255,0,255),3)\n",
        "                label_ = LABELS[y_pred_]\n",
        "                cv2.putText(img2,f'{label_}',(x1,y1),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2)\n",
        "            end = time.time()\n",
        "        print(\"\\tImage {}: {}\".format(img_id, end - start))\n",
        "        plt.imshow(img2)\n",
        "        plt.axis('off')\n",
        "        plt.savefig(os.path.join(test_output_fd, '{}_result.png'.format(img_id)), bbox_inches='tight',dpi=300)\n",
        "        plt.plot\n",
        "\n"
      ],
      "metadata": {
        "id": "VJQ7sRRUvvBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXTjFyKe3qEJ",
        "outputId": "993f3b97-7fcd-429a-8ea7-27ef7148dbea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 4, 1, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk-94i844KEi",
        "outputId": "128433f6-3c3e-4a44-9516-f6bc8aa14c1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of     index  xmin  ymin  xmax  ymax  label_id  label_text  \\\n",
              "0       0   396    -1   575    17         0       OTHER   \n",
              "1       1   352    56   398    71         0       OTHER   \n",
              "2       2   222   112   528   131        16     ADDRESS   \n",
              "3       3   322   132   429   146         0       OTHER   \n",
              "4       4    88   152   234   169        17   TIMESTAMP   \n",
              "5       5   302   192   450   207         0       OTHER   \n",
              "6       6    90   216   238   231         0       OTHER   \n",
              "7       7   346   208   408   219         0       OTHER   \n",
              "8       8    88   232   138   243         0       OTHER   \n",
              "9       9    88   246   160   259         0       OTHER   \n",
              "10     10    86   278   278   295         0       OTHER   \n",
              "11     11   164   368   222   383         0       OTHER   \n",
              "12     12   372   370   390   381         0       OTHER   \n",
              "13     13   584   370   656   385         0       OTHER   \n",
              "14     14    91   403   148   420         0       OTHER   \n",
              "15     15    92   386   612   405         0       OTHER   \n",
              "16     16   140   430   250   443         0       OTHER   \n",
              "17     17   604   432   654   447         0       OTHER   \n",
              "18     18    92   474   310   491         0       OTHER   \n",
              "19     19   140   498   246   509         0       OTHER   \n",
              "20     20   608   496   662   507         0       OTHER   \n",
              "21     21    88   542   172   559         0       OTHER   \n",
              "22     22   140   566   240   581         0       OTHER   \n",
              "23     23   622   564   668   577         0       OTHER   \n",
              "24     24    86   620   436   631         0       OTHER   \n",
              "25     25   132   640   250   655         0       OTHER   \n",
              "26     26   616   632   672   649         0       OTHER   \n",
              "27     27    84   696   568   703         0       OTHER   \n",
              "28     28   138   718   242   733         0       OTHER   \n",
              "29     29   620   710   676   723         0       OTHER   \n",
              "30     30    84   774   456   781         0       OTHER   \n",
              "31     31   138   796   242   811         0       OTHER   \n",
              "32     32   622   782   678   799         0       OTHER   \n",
              "33     33    82   852   396   861         0       OTHER   \n",
              "34     34   780   936   804   953         0       OTHER   \n",
              "35     35    91   965   391   968         0       OTHER   \n",
              "36     36   413  1029   624  1039         0       OTHER   \n",
              "37     37    83  1040   160  1056         0       OTHER   \n",
              "38     38   633  1046   692  1062         0       OTHER   \n",
              "39     39   126  1068   246  1081         0       OTHER   \n",
              "40     40    70  1128   262  1141         0       OTHER   \n",
              "41     41   640  1128   700  1147         0       OTHER   \n",
              "42     42   126  1154   236  1169         0       OTHER   \n",
              "43     43   344  1232   460  1249        18  TOTAL_COST   \n",
              "44     44   636  1222   706  1232        18  TOTAL_COST   \n",
              "45     45   374  1256   460  1273         0       OTHER   \n",
              "46     46   640  1272   710  1283         0       OTHER   \n",
              "47     47   376  1280   460  1301         0       OTHER   \n",
              "48     48   178  1352   718  1331         0       OTHER   \n",
              "49     49   387  1354   466  1364         0       OTHER   \n",
              "\n",
              "                                              content  line_number  right  \\\n",
              "0                           Thomeswoothimmer ham lang            1    NaN   \n",
              "1                                               Sweet            2    NaN   \n",
              "2   33 173 Nguyễn Thượng Hiến - Quận Hai Bà Trưng,...            3    NaN   \n",
              "3                                        011014034333            4    NaN   \n",
              "4                                Ngày bản: 14/08/2020            5    NaN   \n",
              "5                                    HOÁ ĐƠN BÁN HÀNG            6    NaN   \n",
              "6                                Khách hàng: Khách lè            7    7.0   \n",
              "7                                            HDO12613            7    NaN   \n",
              "8                                            Địa chỉ:            8    NaN   \n",
              "9                                          Điện thoại            9    NaN   \n",
              "10                          Người bán: Nguyễn Yến Chi           10    NaN   \n",
              "11                                            Đơn giá           11   12.0   \n",
              "12                                                 SL           11   13.0   \n",
              "13                                         Thành tiền           11    NaN   \n",
              "14                                            (Chiếc)           12   15.0   \n",
              "15  Gilaga Givi thủy tinh bầu thấp miệng loe S1 - ...           12    NaN   \n",
              "16                                    120,000 150,000           13   17.0   \n",
              "17                                            120,000           13    NaN   \n",
              "18                      Hồng treo gió Hoshigaki 250gr           14    NaN   \n",
              "19                                     95,000 438,000           15   20.0   \n",
              "20                                            190,000           15    NaN   \n",
              "21                                          Nến Aroma           16    NaN   \n",
              "22                                      46,000 65,000           17   23.0   \n",
              "23                                             46,000           17    NaN   \n",
              "24    LK LK - KCC Bình sữa 660ml - cao 17cm. đk 7.5cm           18    NaN   \n",
              "25                                    196,000 245,000           19   26.0   \n",
              "26                                            196,000           19    NaN   \n",
              "27  LK - KÁC chén cơm cao 6cm Đk miệng 11 cm - cao...           20    NaN   \n",
              "28                                      52,000 65,000           21   29.0   \n",
              "29                                            156,000           21    NaN   \n",
              "30     WP - KAC cốc đỏ không quai - Cao: 7cm, Đk: 8cm           22    NaN   \n",
              "31                                      36,000 46,000           23   32.0   \n",
              "32                                            180,000           23    NaN   \n",
              "33           LK - KAC tô phở / tô ngũ cốc - dk 14x7cm           24    NaN   \n",
              "34                                                1/2           25    NaN   \n",
              "35          https://homesweethome.kiotviet.vn/sale/H/           26    NaN   \n",
              "36                           HomeSweethome - Bán hàng           27    NaN   \n",
              "37                                          8/14/2020           28   38.0   \n",
              "38                                            192,000           28    NaN   \n",
              "39                                     96,000 420,000           29    NaN   \n",
              "40                             LK - KCC Đĩa tròn 20cm           30   41.0   \n",
              "41                                            380,000           30    NaN   \n",
              "42                                      76,000 95,000           31    NaN   \n",
              "43                                    Tổng tiền hàng:           32   44.0   \n",
              "44                                          1,460,000           32    NaN   \n",
              "45                                        Chiết khấu:           33   46.0   \n",
              "46                                          1,460,000           33    NaN   \n",
              "47                                         Tổng cộng:           34    NaN   \n",
              "48  và tha tra hàng trong vòng 3 ngày với hoà đơn ...           35    NaN   \n",
              "49                                        Swaethlomel           36    NaN   \n",
              "\n",
              "    ...   top      rd_b      rd_t      rd_r      rd_l  n_upper  n_alpha  \\\n",
              "0   ...   NaN  0.028343  0.000000  0.000000  0.000000        1       23   \n",
              "1   ...   0.0  0.029797 -0.028343  0.000000  0.000000        1        5   \n",
              "2   ...   1.0  0.000727 -0.029797  0.000000  0.000000        9       35   \n",
              "3   ...   2.0  0.033430 -0.000727  0.000000  0.000000        0        0   \n",
              "4   ...   NaN  0.034157  0.000000  0.000000  0.000000        1        7   \n",
              "5   ...   3.0  0.000727 -0.033430  0.000000  0.000000       13       13   \n",
              "6   ...   4.0  0.000727 -0.034157  0.120536  0.000000        2       16   \n",
              "7   ...   5.0  0.109738 -0.000727  0.000000 -0.120536        3        3   \n",
              "8   ...   6.0  0.002180 -0.000727  0.000000  0.000000        1        6   \n",
              "9   ...   8.0  0.013808 -0.002180  0.000000  0.000000        1        9   \n",
              "10  ...   9.0  0.053052 -0.013808  0.000000  0.000000        4       20   \n",
              "11  ...  10.0  0.002180 -0.053052  0.167411  0.000000        1        6   \n",
              "12  ...   7.0  0.173692 -0.109738  0.216518 -0.167411        2        2   \n",
              "13  ...   NaN  0.034157  0.000000  0.000000 -0.216518        1        9   \n",
              "14  ...   NaN  0.007267  0.000000 -0.062500  0.000000        1        5   \n",
              "15  ...  11.0  0.050145 -0.002180  0.000000  0.062500        5       53   \n",
              "16  ...  14.0  0.039971 -0.007267  0.395089  0.000000        0        0   \n",
              "17  ...  13.0  0.035610 -0.034157  0.000000 -0.395089        0        0   \n",
              "18  ...  15.0  0.037064 -0.050145  0.000000  0.000000        2       22   \n",
              "19  ...  16.0  0.041424 -0.039971  0.404018  0.000000        0        0   \n",
              "20  ...  17.0  0.041424 -0.035610  0.000000 -0.404018        0        0   \n",
              "21  ...  18.0  0.058866 -0.037064  0.000000  0.000000        2        8   \n",
              "22  ...  19.0  0.083576 -0.041424  0.426339  0.000000        0        0   \n",
              "23  ...  20.0  0.039971 -0.041424  0.000000 -0.426339        0        0   \n",
              "24  ...  12.0  0.063227 -0.173692  0.000000  0.000000        8       25   \n",
              "25  ...  21.0  0.086483 -0.058866  0.408482  0.000000        0        0   \n",
              "26  ...  23.0  0.044331 -0.039971  0.000000 -0.408482        0        0   \n",
              "27  ...  22.0  0.067587 -0.083576  0.000000  0.000000        6       35   \n",
              "28  ...  24.0  0.086483 -0.063227  0.421875  0.000000        0        0   \n",
              "29  ...  26.0  0.042878 -0.044331  0.000000 -0.421875        0        0   \n",
              "30  ...  25.0  0.133721 -0.086483  0.000000  0.000000        7       28   \n",
              "31  ...  27.0  0.166424 -0.067587  0.424107  0.000000        0        0   \n",
              "32  ...  29.0  0.167151 -0.042878  0.000000 -0.424107        0        0   \n",
              "33  ...  28.0  0.150436 -0.086483  0.000000  0.000000        5       23   \n",
              "34  ...   NaN  0.000000  0.000000  0.000000  0.000000        0        0   \n",
              "35  ...  30.0  0.116279 -0.133721  0.000000  0.000000        1       33   \n",
              "36  ...  32.0  0.140262 -0.167151  0.000000  0.000000        3       20   \n",
              "37  ...  31.0  0.071221 -0.166424  0.527902  0.000000        0        0   \n",
              "38  ...   NaN  0.047965  0.000000  0.000000 -0.527902        0        0   \n",
              "39  ...  33.0  0.196948 -0.150436  0.000000  0.000000        0        0   \n",
              "40  ...  35.0  0.000000 -0.116279  0.421875  0.000000        6       14   \n",
              "41  ...  38.0  0.054506 -0.047965  0.000000 -0.421875        0        0   \n",
              "42  ...  37.0  0.000000 -0.071221  0.000000  0.000000        0        0   \n",
              "43  ...  36.0  0.005087 -0.140262  0.196429  0.000000        1       12   \n",
              "44  ...  41.0  0.029070 -0.054506  0.000000 -0.196429        0        0   \n",
              "45  ...  43.0  0.005087 -0.005087  0.200893  0.000000        1        9   \n",
              "46  ...  44.0  0.000000 -0.029070  0.000000 -0.200893        0        0   \n",
              "47  ...  45.0  0.038517 -0.005087  0.000000  0.000000        1        8   \n",
              "48  ...  39.0  0.000000 -0.196948  0.000000  0.000000        1       74   \n",
              "49  ...  47.0  0.000000 -0.038517  0.000000  0.000000        1       11   \n",
              "\n",
              "    n_spaces  n_numeric  n_special  \n",
              "0          2          0          0  \n",
              "1          0          0          0  \n",
              "2         11          5          2  \n",
              "3          0         12          0  \n",
              "4          2          8          3  \n",
              "5          3          0          0  \n",
              "6          3          0          1  \n",
              "7          0          5          0  \n",
              "8          1          0          1  \n",
              "9          1          0          0  \n",
              "10         4          0          1  \n",
              "11         1          0          0  \n",
              "12         0          0          0  \n",
              "13         1          0          0  \n",
              "14         0          0          2  \n",
              "15        15          5          2  \n",
              "16         1         12          2  \n",
              "17         0          6          1  \n",
              "18         4          3          0  \n",
              "19         1         11          2  \n",
              "20         0          6          1  \n",
              "21         1          0          0  \n",
              "22         1         10          2  \n",
              "23         0          5          1  \n",
              "24        11          7          4  \n",
              "25         1         12          2  \n",
              "26         0          6          1  \n",
              "27        16          6          3  \n",
              "28         1         10          2  \n",
              "29         0          6          1  \n",
              "30        11          2          5  \n",
              "31         1         10          2  \n",
              "32         0          6          1  \n",
              "33        11          3          3  \n",
              "34         0          2          1  \n",
              "35         0          0          8  \n",
              "36         3          0          1  \n",
              "37         0          7          2  \n",
              "38         0          6          1  \n",
              "39         1         11          2  \n",
              "40         5          2          1  \n",
              "41         0          6          1  \n",
              "42         1         10          2  \n",
              "43         2          0          1  \n",
              "44         0          7          2  \n",
              "45         1          0          1  \n",
              "46         0          7          2  \n",
              "47         1          0          1  \n",
              "48        23          1          1  \n",
              "49         0          0          0  \n",
              "\n",
              "[50 rows x 22 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}